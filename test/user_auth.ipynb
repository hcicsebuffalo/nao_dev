{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Model\n",
    "from pyannote.audio import Inference\n",
    "# import torch\n",
    "import whisper\n",
    "import openai\n",
    "import json\n",
    "import pyaudio\n",
    "import wave\n",
    "import os\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the token from \"https://huggingface.co/settings/tokens\"\n",
    "<br> More info \"https://huggingface.co/pyannote/embedding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to record audio\n",
    "def record_audio(path, filename, duration):\n",
    "    # Set the parameters for the audio stream\n",
    "    chunk = 1024\n",
    "    sample_format = pyaudio.paInt16\n",
    "    channels = 1\n",
    "    fs = 44100\n",
    "    \n",
    "    # Initialize the PyAudio object\n",
    "    p = pyaudio.PyAudio()\n",
    "    \n",
    "    # Open the audio stream\n",
    "    stream = p.open(format=sample_format,\n",
    "                    channels=channels,\n",
    "                    rate=fs,\n",
    "                    frames_per_buffer=chunk,\n",
    "                    input=True)\n",
    "    \n",
    "    frames = []\n",
    "    \n",
    "    # Record the audio for the specified duration\n",
    "    for i in range(int(fs / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "    \n",
    "    # Stop and close the audio stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    \n",
    "    # Terminate the PyAudio object\n",
    "    p.terminate()\n",
    "    \n",
    "    # Save the recorded audio as a WAV file\n",
    "    file_path = os.path.join(path, filename)\n",
    "    wf = wave.open(file_path, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "    wf.setframerate(fs)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    # Convert the WAV file to MP3\n",
    "    # os.system(f\"ffmpeg -i {filename} -acodec libmp3lame -aq 4 {filename[:-4]}.mp3\")\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage: Record 7 seconds of audio and save it as \"recording.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"What do you want to know?\")\n",
    "record_audio(\"/home/sougato97/Human_Robot_Interaction/nao_dev/recordings\", \"sougato_template.mp3\", 7)\n",
    "print(\"Question recorded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"What do you want to know?\")\n",
    "record_audio(\"/home/sougato97/Human_Robot_Interaction/nao_dev/recordings\", \"recording_sougato_1.mp3\", 7)\n",
    "print(\"Question recorded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"What do you want to know?\")\n",
    "record_audio(\"/home/sougato97/Human_Robot_Interaction/nao_dev/recordings\", \"recording_sougato_3.mp3\", 7)\n",
    "print(\"Question recorded!!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Authentication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyannote_model = Model.from_pretrained(\"pyannote/embedding\", \n",
    "                              use_auth_token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_clip_path = \"/home/sougato97/Human_Robot_Interaction/nao_dev/recordings/\"\n",
    "inference = Inference(pyannote_model, window=\"whole\", device=\"cuda\")\n",
    "# # Define device to be used (GPU or CPU)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "embedding_sougato1 = inference(voice_clip_path + \"sougato_template.mp3\")\n",
    "embedding_sougato2 = inference(voice_clip_path + \"recording_sougato_1.mp3\")\n",
    "embedding_sougato3 = inference(voice_clip_path + \"recording_sougato_3.mp3\")\n",
    "embedding_su1 = inference(voice_clip_path + \"recording_su_1.mp3\")\n",
    "embedding_su2 = inference(voice_clip_path + \"recording_su_2.mp3\")\n",
    "embedding_subhobrata1 = inference(voice_clip_path + \"recording_subhobrata_1.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsqueezed_sougato1 = np.expand_dims(embedding_sougato1, axis=0)\n",
    "unsqueezed_sougato2 = np.expand_dims(embedding_sougato2, axis=0)\n",
    "unsqueezed_sougato3 = np.expand_dims(embedding_sougato3, axis=0)\n",
    "\n",
    "unsqueezed_subhobrata1 = np.expand_dims(embedding_subhobrata1, axis=0)\n",
    "unsqueezed_su1 = np.expand_dims(embedding_su1, axis=0)\n",
    "unsqueezed_su2 = np.expand_dims(embedding_su2, axis=0)\n",
    "\n",
    "distance1 = cdist(unsqueezed_sougato1, unsqueezed_sougato2, metric=\"cosine\")[0,0]\n",
    "distance2 = cdist(unsqueezed_sougato1, unsqueezed_sougato3, metric=\"cosine\")[0,0]\n",
    "distance3 = cdist(unsqueezed_su1, unsqueezed_su2, metric=\"cosine\")[0,0]\n",
    "distance4 = cdist(unsqueezed_sougato1, unsqueezed_subhobrata1, metric=\"cosine\")[0,0]\n",
    "distance5 = cdist(unsqueezed_sougato1, unsqueezed_su1, metric=\"cosine\")[0,0]\n",
    "distance6 = cdist(unsqueezed_subhobrata1, unsqueezed_su1, metric=\"cosine\")[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsqueezed_sougato1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gmaps import Geocoding\n",
    "# api = Geocoding()\n",
    "# api.geocode(\"somewhere\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create a 1D array\n",
    "arr = np.array([[[1], [2], [3]]])\n",
    "\n",
    "# squeeze the array to remove the singleton dimension\n",
    "arr_squeezed = np.squeeze(arr)\n",
    "\n",
    "print(arr_squeezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "directory = \"/home/sougato97/Human_Robot_Interaction/nao_dev/recordings/\"\n",
    "# list all files in directory\n",
    "# for filename in os.listdir(directory):\n",
    "#     # check if the current file name contains the substring\n",
    "#     if 'template' in filename:\n",
    "#         # print the full path of the file\n",
    "#         print(filename)\n",
    "\n",
    "\n",
    "\n",
    "flag = 0 \n",
    "# list all files in directory\n",
    "for filename in os.listdir(directory):\n",
    "    # check if the current file name contains the substring\n",
    "    if 'template' in filename:\n",
    "        inference = Inference(pyannote_model, window=\"whole\", device=\"cuda\")\n",
    "        ref = inference(directory + filename)\n",
    "        recording = inference(directory + \"recording_sougato_1.mp3\")\n",
    "\n",
    "        # Convert these 1d Numpy to 2d numpy array \n",
    "        unsqueezed_ref = np.expand_dims(ref, axis=0)\n",
    "        unsqueezed_rec = np.expand_dims(recording, axis=0)\n",
    "\n",
    "        # Compute the distance\n",
    "        distance1 = cdist(unsqueezed_ref, unsqueezed_rec, metric=\"cosine\")[0,0]\n",
    "\n",
    "        if (distance1 < 0.50):\n",
    "            flag = 1\n",
    "\n",
    "print(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_auth(voice_clip_path, name,pyannote_key):\n",
    "  \n",
    "  pyannote_model = Model.from_pretrained(\"pyannote/embedding\", use_auth_token = pyannote_key)\n",
    "  # Define device to be used (GPU or CPU)\n",
    "  Device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  inference = Inference(pyannote_model, window=\"whole\", device = Device)\n",
    "\n",
    "  flag = 0 \n",
    "  # list all files in directory\n",
    "  for filename in os.listdir(voice_clip_path):\n",
    "    # check if the current file name contains the substring\n",
    "    if 'template' in filename:\n",
    "      ref = inference(voice_clip_path + filename)\n",
    "      recording = inference(voice_clip_path + name)\n",
    "\n",
    "      # Convert these 1d Numpy to 2d numpy array \n",
    "      unsqueezed_ref = np.expand_dims(ref, axis=0)\n",
    "      unsqueezed_rec = np.expand_dims(recording, axis=0)\n",
    "\n",
    "      # Compute the distance\n",
    "      distance1 = cdist(unsqueezed_ref, unsqueezed_rec, metric=\"cosine\")[0,0]\n",
    "\n",
    "      if (distance1 < 0.50):\n",
    "        flag = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Example usage: Record 7 seconds of audio and save it as \"recording.mp3\"\n",
    "    while (1):\n",
    "        # print(\"What do you want to know?\")\n",
    "        # record_audio(voice_clip_path, \"recording.mp3\", 7)\n",
    "        # print(\"Question recorded!!\")\n",
    "        # flag = user_auth(voice_clip_path, \"recording.mp3\", pyannote_key)\n",
    "        \n",
    "        execute_flag = input(\"Do you want the code to exit? Yes, press:1 ; No, press:Any key \")\n",
    "        if (execute_flag == 1):\n",
    "            exit()\n",
    "        else:\n",
    "            print(\"abcd\")\n",
    "            continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original String :  Hello, World!\n",
      "Resultant String :  Hello World\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Initialize the input string\n",
    "input_str = \"Hello, World!\"\n",
    "\n",
    "# Print the original string\n",
    "print(\"Original String : \", input_str)\n",
    "\n",
    "# Loop through each punctuation character in the string.punctuation constant\n",
    "for char in string.punctuation:\n",
    "    # Use the replace() method to remove each punctuation character from the input string\n",
    "    input_str = input_str.replace(char, \"\")\n",
    "\n",
    "# Print the resulting string after removing punctuations\n",
    "print(\"Resultant String : \", input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyglet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
