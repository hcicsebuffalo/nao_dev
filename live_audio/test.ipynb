{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "# import websockets\n",
    "# import asyncio\n",
    "# import json\n",
    "import whisper\n",
    "import numpy as np\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up audio stream parameters\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a Whisper model\n",
    "model = whisper.load_model(\"base.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5007:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM sysdefault\n",
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5007:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM sysdefault\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.front\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround40\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround41\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround50\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround51\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround71\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5007:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM default\n",
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5007:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM default\n",
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5007:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM dmix\n"
     ]
    }
   ],
   "source": [
    "# Create an audio stream with PyAudio\n",
    "audio = pyaudio.PyAudio()\n",
    "stream = audio.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " You\n",
      " You\n",
      " You\n",
      " You\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " . . . . . . .\n",
      " You\n",
      " You\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mShortTensor(data)\n\u001b[1;32m      6\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m----> 7\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtranscribe(data)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(result[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/whisper/transcribe.py:229\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    226\u001b[0m mel_segment \u001b[39m=\u001b[39m pad_or_trim(mel_segment, N_FRAMES)\u001b[39m.\u001b[39mto(model\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mto(dtype)\n\u001b[1;32m    228\u001b[0m decode_options[\u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[0;32m--> 229\u001b[0m result: DecodingResult \u001b[39m=\u001b[39m decode_with_fallback(mel_segment)\n\u001b[1;32m    230\u001b[0m tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(result\u001b[39m.\u001b[39mtokens)\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m no_speech_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39m# no voice activity check\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/whisper/transcribe.py:164\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    161\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mbest_of\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m options \u001b[39m=\u001b[39m DecodingOptions(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, temperature\u001b[39m=\u001b[39mt)\n\u001b[0;32m--> 164\u001b[0m decode_result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdecode(segment, options)\n\u001b[1;32m    166\u001b[0m needs_fallback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    168\u001b[0m     compression_ratio_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mand\u001b[39;00m decode_result\u001b[39m.\u001b[39mcompression_ratio \u001b[39m>\u001b[39m compression_ratio_threshold\n\u001b[1;32m    170\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/whisper/decoding.py:811\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[1;32m    809\u001b[0m     options \u001b[39m=\u001b[39m replace(options, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 811\u001b[0m result \u001b[39m=\u001b[39m DecodingTask(model, options)\u001b[39m.\u001b[39;49mrun(mel)\n\u001b[1;32m    813\u001b[0m \u001b[39mreturn\u001b[39;00m result[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m single \u001b[39melse\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/whisper/decoding.py:724\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    721\u001b[0m tokens \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39mrepeat_interleave(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_group, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(audio_features\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    723\u001b[0m \u001b[39m# call the main sampling loop\u001b[39;00m\n\u001b[0;32m--> 724\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_main_loop(audio_features, tokens)\n\u001b[1;32m    726\u001b[0m \u001b[39m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n\u001b[1;32m    727\u001b[0m audio_features \u001b[39m=\u001b[39m audio_features[:: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_group]\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/whisper/decoding.py:673\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    672\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_len):\n\u001b[0;32m--> 673\u001b[0m         logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference\u001b[39m.\u001b[39;49mlogits(tokens, audio_features)\n\u001b[1;32m    675\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    676\u001b[0m             i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mno_speech \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    677\u001b[0m         ):  \u001b[39m# save no_speech_probs\u001b[39;00m\n\u001b[1;32m    678\u001b[0m             probs_at_sot \u001b[39m=\u001b[39m logits[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msot_index]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39msoftmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/whisper/decoding.py:157\u001b[0m, in \u001b[0;36mPyTorchInference.logits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m tokens\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_token_length:\n\u001b[1;32m    154\u001b[0m     \u001b[39m# only need to use the last token except in the first forward pass\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     tokens \u001b[39m=\u001b[39m tokens[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mdecoder(tokens, audio_features, kv_cache\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkv_cache)\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/whisper/model.py:211\u001b[0m, in \u001b[0;36mTextDecoder.forward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    208\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(xa\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    210\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[0;32m--> 211\u001b[0m     x \u001b[39m=\u001b[39m block(x, xa, mask\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmask, kv_cache\u001b[39m=\u001b[39;49mkv_cache)\n\u001b[1;32m    213\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln(x)\n\u001b[1;32m    214\u001b[0m logits \u001b[39m=\u001b[39m (\n\u001b[1;32m    215\u001b[0m     x \u001b[39m@\u001b[39m torch\u001b[39m.\u001b[39mtranspose(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_embedding\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdtype), \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    216\u001b[0m )\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/whisper/model.py:138\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    136\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn_ln(x), mask\u001b[39m=\u001b[39mmask, kv_cache\u001b[39m=\u001b[39mkv_cache)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcross_attn:\n\u001b[0;32m--> 138\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcross_attn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcross_attn_ln(x), xa, kv_cache\u001b[39m=\u001b[39;49mkv_cache)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    139\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_ln(x))\n\u001b[1;32m    140\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/whisper/model.py:78\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m     72\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     73\u001b[0m     x: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     kv_cache: Optional[\u001b[39mdict\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     77\u001b[0m ):\n\u001b[0;32m---> 78\u001b[0m     q \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery(x)\n\u001b[1;32m     80\u001b[0m     \u001b[39mif\u001b[39;00m kv_cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m xa \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kv_cache:\n\u001b[1;32m     81\u001b[0m         \u001b[39m# hooks, if installed (i.e. kv_cache is not None), will prepend the cached kv tensors;\u001b[39;00m\n\u001b[1;32m     82\u001b[0m         \u001b[39m# otherwise, perform key/value projections for self- or cross-attention as usual.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey(x \u001b[39mif\u001b[39;00m xa \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m xa)\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hri/lib/python3.10/site-packages/whisper/model.py:37\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 37\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\n\u001b[1;32m     38\u001b[0m         x,\n\u001b[1;32m     39\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mto(x\u001b[39m.\u001b[39;49mdtype),\n\u001b[1;32m     40\u001b[0m         \u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias\u001b[39m.\u001b[39;49mto(x\u001b[39m.\u001b[39;49mdtype),\n\u001b[1;32m     41\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Transcribe the audio stream with Whisper\n",
    "while True:\n",
    "    data = stream.read(CHUNK)\n",
    "    data = np.frombuffer(data, dtype=np.int16)\n",
    "    data = torch.ShortTensor(data)\n",
    "    data = data.float()\n",
    "    result = model.transcribe(data)\n",
    "    print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "buffer size must be a multiple of element size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     audio_bytes \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m----> 7\u001b[0m new_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mfrombuffer(audio_bytes, dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfloat64\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtranscribe(audio_bytes)\n",
      "\u001b[0;31mValueError\u001b[0m: buffer size must be a multiple of element size"
     ]
    }
   ],
   "source": [
    "path = '/home/sougato97/Human_Robot_Interaction/nao_dev/recordings/recording_sougato_3.mp3'\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    audio_bytes = f.read()\n",
    "\n",
    "\n",
    "new_arr = np.frombuffer(audio_bytes, dtype=\"int64\")\n",
    "result = model.transcribe(audio_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sougato97/Human_Robot_Interaction/nao_dev/recordings/recording_sougato_3.mp3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create a numpy array\n",
    "arr = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "# convert numpy array to bytes\n",
    "bytes_arr = arr.tobytes()\n",
    "\n",
    "# convert bytes back to numpy array\n",
    "new_arr = np.frombuffer(bytes_arr, dtype=arr.dtype)\n",
    "\n",
    "print(new_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
